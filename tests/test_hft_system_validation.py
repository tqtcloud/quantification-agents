"""
é«˜é¢‘äº¤æ˜“ç³»ç»Ÿå®Œæ•´æµ‹è¯•éªŒè¯å¥—ä»¶

æµ‹è¯•åŒ…å«ï¼š
1. æ€§èƒ½æµ‹è¯• - å»¶è¿Ÿã€ååé‡ã€èµ„æºä½¿ç”¨
2. åŠŸèƒ½æµ‹è¯• - å»¶è¿Ÿç›‘æ§ã€ä¿¡å·å¤„ç†ã€è®¢å•ç”Ÿæˆ
3. é›†æˆæµ‹è¯• - ç«¯åˆ°ç«¯æµç¨‹éªŒè¯
4. å¯é æ€§æµ‹è¯• - æ•…éšœæ¢å¤ã€å¹¶å‘å®‰å…¨
"""

import pytest
import asyncio
import time
import statistics
import gc
import psutil
import os
from datetime import datetime, timedelta
from typing import List, Dict, Any
from unittest.mock import Mock, patch, MagicMock
from dataclasses import asdict

import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

# å¯¼å…¥å¾…æµ‹è¯•æ¨¡å—
from src.hft.latency_monitor import LatencyMonitor, DataSource, LatencyAlert
from src.hft.integrated_signal_processor import IntegratedHFTSignalProcessor
from src.hft.smart_order_router import SmartOrderRouter, OrderRequest
from src.hft.fault_tolerance_manager import FaultToleranceManager
from src.core.models.signals import TradingSignal, MultiDimensionalSignal, SignalStrength


class TestSystemPerformance:
    """ç³»ç»Ÿæ€§èƒ½æµ‹è¯•"""
    
    @pytest.fixture
    def setup_system_components(self):
        """è®¾ç½®ç³»ç»Ÿç»„ä»¶"""
        latency_monitor = LatencyMonitor(threshold_ms=100)
        signal_processor = IntegratedHFTSignalProcessor()
        order_router = SmartOrderRouter()
        fault_manager = FaultToleranceManager()
        
        return {
            'latency_monitor': latency_monitor,
            'signal_processor': signal_processor,
            'order_router': order_router,
            'fault_manager': fault_manager
        }
    
    @pytest.mark.asyncio
    async def test_signal_generation_latency(self, setup_system_components):
        """æµ‹è¯•ä¿¡å·ç”Ÿæˆå»¶è¿Ÿæ€§èƒ½ - ç›®æ ‡ < 10ms"""
        components = setup_system_components
        signal_processor = components['signal_processor']
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_data = {
            'symbol': 'BTCUSDT',
            'price': 45000.0,
            'volume': 1000,
            'timestamp': datetime.now().timestamp() * 1000
        }
        
        latencies = []
        iterations = 100
        
        for _ in range(iterations):
            start_time = time.perf_counter()
            
            # ç”Ÿæˆäº¤æ˜“ä¿¡å·
            signal = await signal_processor.process_signal(test_data)
            
            end_time = time.perf_counter()
            latency_ms = (end_time - start_time) * 1000
            latencies.append(latency_ms)
        
        # æ€§èƒ½æŒ‡æ ‡è®¡ç®—
        avg_latency = statistics.mean(latencies)
        p95_latency = statistics.quantiles(latencies, n=20)[18]  # 95th percentile
        p99_latency = statistics.quantiles(latencies, n=100)[98]  # 99th percentile
        max_latency = max(latencies)
        
        print(f"\n=== ä¿¡å·ç”Ÿæˆå»¶è¿Ÿæ€§èƒ½æµ‹è¯•ç»“æœ ===")
        print(f"å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms")
        print(f"P95å»¶è¿Ÿ: {p95_latency:.2f}ms")
        print(f"P99å»¶è¿Ÿ: {p99_latency:.2f}ms")
        print(f"æœ€å¤§å»¶è¿Ÿ: {max_latency:.2f}ms")
        
        # æ€§èƒ½æ–­è¨€
        assert avg_latency < 10.0, f"å¹³å‡å»¶è¿Ÿ {avg_latency:.2f}ms è¶…è¿‡ç›®æ ‡ 10ms"
        assert p95_latency < 15.0, f"P95å»¶è¿Ÿ {p95_latency:.2f}ms è¶…è¿‡ç›®æ ‡ 15ms"
        assert p99_latency < 25.0, f"P99å»¶è¿Ÿ {p99_latency:.2f}ms è¶…è¿‡ç›®æ ‡ 25ms"
    
    @pytest.mark.asyncio
    async def test_throughput_performance(self, setup_system_components):
        """æµ‹è¯•ç³»ç»Ÿååé‡æ€§èƒ½ - ç›®æ ‡ > 10,000 TPS"""
        components = setup_system_components
        signal_processor = components['signal_processor']
        
        # å‡†å¤‡æ‰¹é‡æµ‹è¯•æ•°æ®
        test_batch = []
        batch_size = 1000
        
        for i in range(batch_size):
            test_batch.append({
                'symbol': f'TEST{i % 100}USDT',
                'price': 45000.0 + i,
                'volume': 1000 + i,
                'timestamp': datetime.now().timestamp() * 1000 + i
            })
        
        # ååé‡æµ‹è¯•
        start_time = time.perf_counter()
        
        # å¹¶å‘å¤„ç†
        tasks = [signal_processor.process_signal(data) for data in test_batch]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = time.perf_counter()
        
        # è®¡ç®—ååé‡
        total_time = end_time - start_time
        throughput = batch_size / total_time
        successful_results = sum(1 for r in results if not isinstance(r, Exception))
        success_rate = successful_results / batch_size
        
        print(f"\n=== ç³»ç»Ÿååé‡æ€§èƒ½æµ‹è¯•ç»“æœ ===")
        print(f"å¤„ç†æ•°é‡: {batch_size}")
        print(f"æ€»è€—æ—¶: {total_time:.2f}s")
        print(f"ååé‡: {throughput:.2f} TPS")
        print(f"æˆåŠŸç‡: {success_rate:.2%}")
        
        # æ€§èƒ½æ–­è¨€
        assert throughput > 5000, f"ååé‡ {throughput:.2f} TPS ä½äºæœ€ä½ç›®æ ‡ 5000 TPS"
        assert success_rate > 0.99, f"æˆåŠŸç‡ {success_rate:.2%} ä½äºç›®æ ‡ 99%"
    
    def test_memory_usage_performance(self, setup_system_components):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨æ€§èƒ½"""
        process = psutil.Process(os.getpid())
        
        # è®°å½•åˆå§‹å†…å­˜ä½¿ç”¨
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # æ‰§è¡Œå†…å­˜å‹åŠ›æµ‹è¯•
        components = setup_system_components
        
        # å¤§é‡æ•°æ®å¤„ç†
        for i in range(1000):
            test_data = {
                'symbol': f'TEST{i}USDT',
                'price': 45000.0 + i,
                'volume': 1000 + i,
                'timestamp': datetime.now().timestamp() * 1000 + i
            }
            
            # æ¨¡æ‹Ÿæ•°æ®å¤„ç†
            components['latency_monitor']._calculate_network_latency(test_data['timestamp'])
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        
        # è®°å½•æœ€ç»ˆå†…å­˜ä½¿ç”¨
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory
        
        print(f"\n=== å†…å­˜ä½¿ç”¨æ€§èƒ½æµ‹è¯•ç»“æœ ===")
        print(f"åˆå§‹å†…å­˜: {initial_memory:.2f}MB")
        print(f"æœ€ç»ˆå†…å­˜: {final_memory:.2f}MB")
        print(f"å†…å­˜å¢é•¿: {memory_increase:.2f}MB")
        
        # å†…å­˜ä½¿ç”¨æ–­è¨€
        assert memory_increase < 50, f"å†…å­˜å¢é•¿ {memory_increase:.2f}MB è¶…è¿‡ç›®æ ‡ 50MB"


class TestFunctionalValidation:
    """åŠŸèƒ½æµ‹è¯•éªŒè¯"""
    
    @pytest.mark.asyncio
    async def test_latency_monitor_functionality(self):
        """æµ‹è¯•å»¶è¿Ÿç›‘æ§åŠŸèƒ½"""
        monitor = LatencyMonitor(threshold_ms=50)
        
        # æ·»åŠ æ•°æ®æº
        primary_source = DataSource(
            name="primary",
            endpoint="ws://primary.com",
            priority=1,
            is_active=True
        )
        backup_source = DataSource(
            name="backup", 
            endpoint="ws://backup.com",
            priority=2,
            is_active=True
        )
        
        await monitor.add_data_source(primary_source)
        await monitor.add_data_source(backup_source)
        
        # æµ‹è¯•æ­£å¸¸å»¶è¿Ÿæ£€æŸ¥
        current_time = datetime.now().timestamp() * 1000
        fresh_timestamp = current_time - 30  # 30mså‰
        
        is_fresh, latency = await monitor.check_data_freshness(fresh_timestamp)
        
        assert is_fresh == True, "æ–°é²œæ•°æ®åº”è¯¥é€šè¿‡æ£€æŸ¥"
        assert latency < 50, f"å»¶è¿Ÿ {latency}ms åº”è¯¥ä½äºé˜ˆå€¼ 50ms"
        
        # æµ‹è¯•è¿‡æœŸæ•°æ®æ£€æŸ¥
        stale_timestamp = current_time - 100  # 100mså‰
        is_fresh, latency = await monitor.check_data_freshness(stale_timestamp)
        
        assert is_fresh == False, "è¿‡æœŸæ•°æ®åº”è¯¥æœªé€šè¿‡æ£€æŸ¥"
        assert latency > 50, f"å»¶è¿Ÿ {latency}ms åº”è¯¥é«˜äºé˜ˆå€¼ 50ms"
        
        print(f"âœ… å»¶è¿Ÿç›‘æ§åŠŸèƒ½æµ‹è¯•é€šè¿‡")
    
    @pytest.mark.asyncio 
    async def test_signal_filtering_logic(self):
        """æµ‹è¯•ä¿¡å·è¿‡æ»¤é€»è¾‘"""
        processor = IntegratedHFTSignalProcessor()
        
        # æµ‹è¯•é«˜è´¨é‡ä¿¡å·ï¼ˆåº”è¯¥é€šè¿‡ï¼‰
        high_quality_signal = MultiDimensionalSignal(
            primary_signal=TradingSignal(
                symbol="BTCUSDT",
                signal_type=SignalStrength.BUY,
                confidence=0.85,
                entry_price=45000.0,
                target_price=46000.0,
                stop_loss=44000.0,
                reasoning=["å¼ºçƒˆä¸Šæ¶¨è¶‹åŠ¿", "æŠ€æœ¯æŒ‡æ ‡ä¸€è‡´çœ‹æ¶¨"],
                indicators_consensus={"rsi": 0.7, "macd": 0.8},
                timestamp=datetime.now()
            ),
            momentum_score=0.8,
            mean_reversion_score=0.6,
            volatility_score=0.4,
            volume_score=0.7,
            sentiment_score=0.6,
            overall_confidence=0.85,
            risk_reward_ratio=2.0,
            max_position_size=1000
        )
        
        should_pass = processor._should_filter_signal(high_quality_signal)
        assert should_pass == False, "é«˜è´¨é‡ä¿¡å·åº”è¯¥é€šè¿‡è¿‡æ»¤å™¨ï¼ˆè¿”å›Falseè¡¨ç¤ºä¸è¿‡æ»¤ï¼‰"
        
        # æµ‹è¯•ä½è´¨é‡ä¿¡å·ï¼ˆåº”è¯¥è¢«è¿‡æ»¤ï¼‰
        low_quality_signal = MultiDimensionalSignal(
            primary_signal=TradingSignal(
                symbol="BTCUSDT",
                signal_type=SignalStrength.WEAK_BUY,
                confidence=0.4,  # ä½ç½®ä¿¡åº¦
                entry_price=45000.0,
                target_price=45500.0,
                stop_loss=44500.0,
                reasoning=["å¾®å¼±ä¿¡å·"],
                indicators_consensus={"rsi": 0.5, "macd": 0.3},
                timestamp=datetime.now()
            ),
            momentum_score=0.2,  # ä½åŠ¨é‡
            mean_reversion_score=0.1,
            volatility_score=0.8,  # é«˜æ³¢åŠ¨ç‡
            volume_score=0.3,
            sentiment_score=0.2,
            overall_confidence=0.4,  # ä½æ•´ä½“ç½®ä¿¡åº¦
            risk_reward_ratio=0.5,  # ä½é£é™©æ”¶ç›Šæ¯”
            max_position_size=100
        )
        
        should_filter = processor._should_filter_signal(low_quality_signal)
        assert should_filter == True, "ä½è´¨é‡ä¿¡å·åº”è¯¥è¢«è¿‡æ»¤å™¨æ‹¦æˆª"
        
        print(f"âœ… ä¿¡å·è¿‡æ»¤é€»è¾‘æµ‹è¯•é€šè¿‡")
    
    @pytest.mark.asyncio
    async def test_order_generation_accuracy(self):
        """æµ‹è¯•è®¢å•ç”Ÿæˆå‡†ç¡®æ€§"""
        router = SmartOrderRouter()
        
        # åˆ›å»ºæµ‹è¯•ä¿¡å·
        test_signal = MultiDimensionalSignal(
            primary_signal=TradingSignal(
                symbol="BTCUSDT",
                signal_type=SignalStrength.STRONG_BUY,
                confidence=0.9,
                entry_price=45000.0,
                target_price=46800.0,  # 4%ç›ˆåˆ©ç›®æ ‡
                stop_loss=43200.0,     # 4%æ­¢æŸ
                reasoning=["å¼ºåŠ¿çªç ´", "é‡ä»·é½å‡"],
                indicators_consensus={"rsi": 0.75, "macd": 0.85},
                timestamp=datetime.now()
            ),
            momentum_score=0.85,
            mean_reversion_score=0.7,
            volatility_score=0.3,
            volume_score=0.8,
            sentiment_score=0.7,
            overall_confidence=0.9,
            risk_reward_ratio=2.0,
            max_position_size=1000
        )
        
        # ç”Ÿæˆè®¢å•
        orders = await router.generate_orders_from_signal(test_signal)
        
        assert len(orders) > 0, "åº”è¯¥ç”Ÿæˆè‡³å°‘ä¸€ä¸ªè®¢å•"
        
        main_order = orders[0]
        assert main_order.symbol == "BTCUSDT", "è®¢å•æ ‡çš„åº”è¯¥åŒ¹é…ä¿¡å·"
        assert main_order.side == "BUY", "åº”è¯¥ç”Ÿæˆä¹°å…¥è®¢å•"
        assert main_order.quantity > 0, "è®¢å•æ•°é‡åº”è¯¥å¤§äº0"
        assert main_order.price <= 45000.0 * 1.001, "é™ä»·è®¢å•ä»·æ ¼åº”è¯¥åˆç†"  # å…è®¸0.1%æº¢ä»·
        
        # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†ä¿æŠ¤æ€§è®¢å•
        has_stop_loss = any(order.order_type in ["STOP_LOSS", "STOP_LOSS_LIMIT"] for order in orders)
        has_take_profit = any("TAKE_PROFIT" in order.order_type for order in orders)
        
        print(f"âœ… è®¢å•ç”Ÿæˆå‡†ç¡®æ€§æµ‹è¯•é€šè¿‡ - ç”Ÿæˆäº†{len(orders)}ä¸ªè®¢å•")
        print(f"   - åŒ…å«æ­¢æŸè®¢å•: {has_stop_loss}")
        print(f"   - åŒ…å«æ­¢ç›ˆè®¢å•: {has_take_profit}")
    
    @pytest.mark.asyncio
    async def test_fault_tolerance_mechanisms(self):
        """æµ‹è¯•å®¹é”™æœºåˆ¶"""
        fault_manager = FaultToleranceManager()
        
        # æµ‹è¯•ç»„ä»¶æ³¨å†Œ
        test_component = Mock()
        test_component.name = "test_component"
        
        fault_manager.register_component("test_component", test_component)
        assert "test_component" in fault_manager.components, "ç»„ä»¶åº”è¯¥æˆåŠŸæ³¨å†Œ"
        
        # æµ‹è¯•é”™è¯¯æ£€æµ‹å’Œåˆ†ç±»
        test_error = ValueError("æµ‹è¯•é”™è¯¯")
        error_type = fault_manager._classify_error(test_error)
        
        assert error_type in fault_manager.error_strategies, f"é”™è¯¯ç±»å‹ {error_type} åº”è¯¥æœ‰å¯¹åº”çš„å¤„ç†ç­–ç•¥"
        
        # æµ‹è¯•ç†”æ–­å™¨åŠŸèƒ½
        circuit_breaker = fault_manager._get_circuit_breaker("test_component")
        
        # æ¨¡æ‹Ÿå¤šæ¬¡å¤±è´¥è§¦å‘ç†”æ–­
        for _ in range(5):
            circuit_breaker.record_failure()
        
        assert circuit_breaker.state == "OPEN", "å¤šæ¬¡å¤±è´¥åç†”æ–­å™¨åº”è¯¥å¼€å¯"
        
        # ç­‰å¾…ç†”æ–­æ¢å¤æ—¶é—´å¹¶æµ‹è¯•åŠå¼€çŠ¶æ€
        circuit_breaker.last_failure_time = time.time() - 61  # æ¨¡æ‹Ÿ60ç§’å
        circuit_breaker._update_state()
        
        assert circuit_breaker.state == "HALF_OPEN", "ç­‰å¾…æ—¶é—´åç†”æ–­å™¨åº”è¯¥è¿›å…¥åŠå¼€çŠ¶æ€"
        
        print(f"âœ… å®¹é”™æœºåˆ¶æµ‹è¯•é€šè¿‡")


class TestIntegrationValidation:
    """é›†æˆæµ‹è¯•éªŒè¯"""
    
    @pytest.fixture
    def integrated_system(self):
        """é›†æˆæµ‹è¯•ç³»ç»Ÿfixture"""
        return {
            'latency_monitor': LatencyMonitor(threshold_ms=100),
            'signal_processor': IntegratedHFTSignalProcessor(),
            'order_router': SmartOrderRouter(),
            'fault_manager': FaultToleranceManager()
        }
    
    @pytest.mark.asyncio
    async def test_end_to_end_trading_flow(self, integrated_system):
        """ç«¯åˆ°ç«¯äº¤æ˜“æµç¨‹æµ‹è¯•"""
        
        # æ¨¡æ‹Ÿå¸‚åœºæ•°æ®è¾“å…¥
        market_data = {
            'symbol': 'BTCUSDT',
            'price': 45000.0,
            'volume': 1500,
            'timestamp': datetime.now().timestamp() * 1000,
            'bid': 44995.0,
            'ask': 45005.0,
            'open': 44800.0,
            'high': 45200.0,
            'low': 44700.0
        }
        
        # Step 1: å»¶è¿Ÿæ£€æŸ¥
        latency_monitor = integrated_system['latency_monitor']
        is_fresh, latency = await latency_monitor.check_data_freshness(market_data['timestamp'])
        
        if not is_fresh:
            pytest.skip(f"æ•°æ®å»¶è¿Ÿ {latency}ms è¿‡é«˜ï¼Œè·³è¿‡æµ‹è¯•")
        
        # Step 2: ä¿¡å·å¤„ç†
        signal_processor = integrated_system['signal_processor']
        
        with patch.object(signal_processor.multidimensional_engine, 'generate_multidimensional_signal') as mock_engine:
            # æ¨¡æ‹Ÿä¿¡å·ç”Ÿæˆ
            mock_signal = MultiDimensionalSignal(
                primary_signal=TradingSignal(
                    symbol="BTCUSDT",
                    signal_type=SignalStrength.BUY,
                    confidence=0.8,
                    entry_price=45000.0,
                    target_price=46800.0,
                    stop_loss=43200.0,
                    reasoning=["è¶‹åŠ¿å‘ä¸Š", "æˆäº¤é‡å¢åŠ "],
                    indicators_consensus={"rsi": 0.7, "macd": 0.75},
                    timestamp=datetime.now()
                ),
                momentum_score=0.8,
                mean_reversion_score=0.6,
                volatility_score=0.4,
                volume_score=0.8,
                sentiment_score=0.6,
                overall_confidence=0.8,
                risk_reward_ratio=2.1,
                max_position_size=800
            )
            mock_engine.return_value = mock_signal
            
            processed_signal = await signal_processor.process_signal(market_data)
        
        assert processed_signal is not None, "åº”è¯¥æˆåŠŸå¤„ç†ä¿¡å·"
        
        # Step 3: è®¢å•ç”Ÿæˆ
        order_router = integrated_system['order_router']
        orders = await order_router.generate_orders_from_signal(processed_signal)
        
        assert len(orders) > 0, "åº”è¯¥ç”Ÿæˆäº¤æ˜“è®¢å•"
        
        # Step 4: è®¢å•è·¯ç”±
        routed_orders = []
        for order in orders:
            routed_order = await order_router.route_order(order)
            routed_orders.append(routed_order)
        
        assert len(routed_orders) == len(orders), "æ‰€æœ‰è®¢å•éƒ½åº”è¯¥æˆåŠŸè·¯ç”±"
        
        # Step 5: éªŒè¯å®Œæ•´æµç¨‹æ—¶é—´
        total_processing_time = (time.time() * 1000) - market_data['timestamp']
        
        print(f"\n=== ç«¯åˆ°ç«¯äº¤æ˜“æµç¨‹æµ‹è¯•ç»“æœ ===")
        print(f"æ•°æ®å»¶è¿Ÿ: {latency:.2f}ms")
        print(f"ä¿¡å·è´¨é‡: {processed_signal.overall_confidence:.2%}")
        print(f"ç”Ÿæˆè®¢å•: {len(orders)}ä¸ª")
        print(f"æ€»å¤„ç†æ—¶é—´: {total_processing_time:.2f}ms")
        
        # æ€§èƒ½æ–­è¨€
        assert total_processing_time < 100, f"æ€»å¤„ç†æ—¶é—´ {total_processing_time:.2f}ms åº”è¯¥ä½äº100ms"
        
        print(f"âœ… ç«¯åˆ°ç«¯äº¤æ˜“æµç¨‹æµ‹è¯•é€šè¿‡")
    
    @pytest.mark.asyncio
    async def test_concurrent_processing(self, integrated_system):
        """å¹¶å‘å¤„ç†æµ‹è¯•"""
        
        # åˆ›å»ºå¤šä¸ªå¹¶å‘æµ‹è¯•ä»»åŠ¡
        test_tasks = []
        num_concurrent = 50
        
        for i in range(num_concurrent):
            market_data = {
                'symbol': f'TEST{i % 10}USDT',
                'price': 45000.0 + i,
                'volume': 1000 + i * 10,
                'timestamp': datetime.now().timestamp() * 1000 + i
            }
            
            # åˆ›å»ºç«¯åˆ°ç«¯å¤„ç†ä»»åŠ¡
            task = self._process_single_request(integrated_system, market_data)
            test_tasks.append(task)
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        start_time = time.perf_counter()
        results = await asyncio.gather(*test_tasks, return_exceptions=True)
        end_time = time.perf_counter()
        
        # åˆ†æç»“æœ
        successful_results = [r for r in results if not isinstance(r, Exception)]
        failed_results = [r for r in results if isinstance(r, Exception)]
        
        success_rate = len(successful_results) / len(results)
        total_time = end_time - start_time
        
        print(f"\n=== å¹¶å‘å¤„ç†æµ‹è¯•ç»“æœ ===")
        print(f"å¹¶å‘æ•°é‡: {num_concurrent}")
        print(f"æˆåŠŸå¤„ç†: {len(successful_results)}")
        print(f"å¤„ç†å¤±è´¥: {len(failed_results)}")
        print(f"æˆåŠŸç‡: {success_rate:.2%}")
        print(f"æ€»è€—æ—¶: {total_time:.2f}s")
        print(f"å¹³å‡å“åº”æ—¶é—´: {total_time / num_concurrent * 1000:.2f}ms")
        
        # å¹¶å‘æ€§èƒ½æ–­è¨€
        assert success_rate > 0.95, f"å¹¶å‘æˆåŠŸç‡ {success_rate:.2%} åº”è¯¥é«˜äº95%"
        assert total_time < 5.0, f"æ€»å¤„ç†æ—¶é—´ {total_time:.2f}s åº”è¯¥ä½äº5ç§’"
        
        print(f"âœ… å¹¶å‘å¤„ç†æµ‹è¯•é€šè¿‡")
    
    async def _process_single_request(self, system, market_data):
        """å¤„ç†å•ä¸ªè¯·æ±‚çš„è¾…åŠ©æ–¹æ³•"""
        try:
            # ç®€åŒ–çš„å¤„ç†æµç¨‹
            latency_monitor = system['latency_monitor'] 
            is_fresh, _ = await latency_monitor.check_data_freshness(market_data['timestamp'])
            
            if is_fresh:
                signal_processor = system['signal_processor']
                # ä½¿ç”¨mocké¿å…å¤æ‚çš„ä¿¡å·ç”Ÿæˆ
                with patch.object(signal_processor, 'process_signal') as mock_process:
                    mock_signal = Mock()
                    mock_signal.overall_confidence = 0.7
                    mock_process.return_value = mock_signal
                    
                    result = await signal_processor.process_signal(market_data)
                    return result
            
            return None
            
        except Exception as e:
            return e


class TestReliabilityValidation:
    """å¯é æ€§æµ‹è¯•éªŒè¯"""
    
    @pytest.mark.asyncio
    async def test_fault_recovery(self):
        """æ•…éšœæ¢å¤æµ‹è¯•"""
        fault_manager = FaultToleranceManager()
        
        # æ³¨å†Œæµ‹è¯•ç»„ä»¶
        test_component = Mock()
        test_component.recover.return_value = True
        fault_manager.register_component("test_service", test_component)
        
        # æ¨¡æ‹Ÿç»„ä»¶æ•…éšœ
        await fault_manager.handle_component_failure("test_service", Exception("æ¨¡æ‹Ÿæ•…éšœ"))
        
        # æ£€æŸ¥ç»„ä»¶çŠ¶æ€
        health_status = await fault_manager.get_system_health()
        
        assert "test_service" in health_status, "æ•…éšœç»„ä»¶åº”è¯¥åœ¨å¥åº·çŠ¶æ€ä¸­è¢«è·Ÿè¸ª"
        
        # æ¨¡æ‹Ÿæ¢å¤è¿‡ç¨‹
        recovery_success = await fault_manager.attempt_recovery("test_service")
        
        print(f"âœ… æ•…éšœæ¢å¤æµ‹è¯•é€šè¿‡ - æ¢å¤çŠ¶æ€: {recovery_success}")
    
    @pytest.mark.asyncio
    async def test_data_consistency(self):
        """æ•°æ®ä¸€è‡´æ€§æµ‹è¯•"""
        
        # åˆ›å»ºå¤šä¸ªå¤„ç†å™¨å®ä¾‹æ¨¡æ‹Ÿåˆ†å¸ƒå¼åœºæ™¯
        processor1 = IntegratedHFTSignalProcessor()
        processor2 = IntegratedHFTSignalProcessor()
        
        # ç›¸åŒè¾“å…¥æ•°æ®
        test_data = {
            'symbol': 'BTCUSDT',
            'price': 45000.0,
            'volume': 1000,
            'timestamp': datetime.now().timestamp() * 1000
        }
        
        # Mockä¿¡å·ç”Ÿæˆä»¥ç¡®ä¿ä¸€è‡´æ€§
        mock_signal = Mock()
        mock_signal.overall_confidence = 0.8
        mock_signal.primary_signal.symbol = 'BTCUSDT'
        
        with patch.multiple(
            processor1,
            _should_filter_signal=Mock(return_value=False),
            multidimensional_engine=Mock()
        ), patch.multiple(
            processor2,
            _should_filter_signal=Mock(return_value=False), 
            multidimensional_engine=Mock()
        ):
            processor1.multidimensional_engine.generate_multidimensional_signal.return_value = mock_signal
            processor2.multidimensional_engine.generate_multidimensional_signal.return_value = mock_signal
            
            # å¹¶è¡Œå¤„ç†ç›¸åŒæ•°æ®
            result1, result2 = await asyncio.gather(
                processor1.process_signal(test_data),
                processor2.process_signal(test_data)
            )
        
        # éªŒè¯ç»“æœä¸€è‡´æ€§
        assert result1 is not None and result2 is not None, "ä¸¤ä¸ªå¤„ç†å™¨éƒ½åº”è¯¥è¿”å›ç»“æœ"
        
        print(f"âœ… æ•°æ®ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
    
    def test_error_handling_coverage(self):
        """é”™è¯¯å¤„ç†è¦†ç›–æµ‹è¯•"""
        fault_manager = FaultToleranceManager()
        
        # æµ‹è¯•ä¸åŒç±»å‹çš„é”™è¯¯å¤„ç†
        error_types = [
            ValueError("å€¼é”™è¯¯"),
            ConnectionError("è¿æ¥é”™è¯¯"), 
            TimeoutError("è¶…æ—¶é”™è¯¯"),
            KeyError("é”®é”™è¯¯"),
            AttributeError("å±æ€§é”™è¯¯"),
            Exception("é€šç”¨å¼‚å¸¸")
        ]
        
        handled_errors = 0
        for error in error_types:
            error_type = fault_manager._classify_error(error)
            if error_type in fault_manager.error_strategies:
                handled_errors += 1
        
        coverage_rate = handled_errors / len(error_types)
        
        print(f"\n=== é”™è¯¯å¤„ç†è¦†ç›–æµ‹è¯•ç»“æœ ===")
        print(f"æµ‹è¯•é”™è¯¯ç±»å‹: {len(error_types)}")
        print(f"å·²å¤„ç†é”™è¯¯: {handled_errors}")
        print(f"è¦†ç›–ç‡: {coverage_rate:.2%}")
        
        assert coverage_rate > 0.8, f"é”™è¯¯å¤„ç†è¦†ç›–ç‡ {coverage_rate:.2%} åº”è¯¥é«˜äº80%"
        
        print(f"âœ… é”™è¯¯å¤„ç†è¦†ç›–æµ‹è¯•é€šè¿‡")


class TestSystemBenchmarks:
    """ç³»ç»ŸåŸºå‡†æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_system_benchmark_suite(self):
        """ç³»ç»ŸåŸºå‡†æµ‹è¯•å¥—ä»¶"""
        print(f"\n{'='*50}")
        print(f"é«˜é¢‘äº¤æ˜“ç³»ç»ŸåŸºå‡†æµ‹è¯•æŠ¥å‘Š")
        print(f"{'='*50}")
        
        # ç³»ç»Ÿä¿¡æ¯
        print(f"\nç³»ç»Ÿä¿¡æ¯:")
        print(f"  CPU: {psutil.cpu_count()}æ ¸")
        print(f"  å†…å­˜: {psutil.virtual_memory().total / 1024**3:.1f}GB")
        print(f"  Python: {sys.version.split()[0]}")
        
        # åŸºå‡†æµ‹è¯•ç»“æœæ±‡æ€»
        benchmark_results = {
            'signal_latency_avg': 0,
            'signal_latency_p99': 0,
            'throughput_tps': 0,
            'memory_usage_mb': 0,
            'success_rate': 0,
            'fault_recovery_time': 0
        }
        
        # æ‰§è¡Œå„é¡¹åŸºå‡†æµ‹è¯•
        latency_results = await self._benchmark_latency()
        throughput_results = await self._benchmark_throughput()
        memory_results = self._benchmark_memory()
        reliability_results = await self._benchmark_reliability()
        
        benchmark_results.update({
            'signal_latency_avg': latency_results['avg'],
            'signal_latency_p99': latency_results['p99'],
            'throughput_tps': throughput_results['tps'],
            'memory_usage_mb': memory_results['peak_mb'],
            'success_rate': reliability_results['success_rate'],
            'fault_recovery_time': reliability_results['recovery_time']
        })
        
        # è¾“å‡ºåŸºå‡†æŠ¥å‘Š
        print(f"\nåŸºå‡†æµ‹è¯•ç»“æœ:")
        print(f"  ä¿¡å·å»¶è¿Ÿ (å¹³å‡): {benchmark_results['signal_latency_avg']:.2f}ms")
        print(f"  ä¿¡å·å»¶è¿Ÿ (P99): {benchmark_results['signal_latency_p99']:.2f}ms") 
        print(f"  ç³»ç»Ÿååé‡: {benchmark_results['throughput_tps']:.0f} TPS")
        print(f"  å†…å­˜ä½¿ç”¨å³°å€¼: {benchmark_results['memory_usage_mb']:.1f}MB")
        print(f"  ç³»ç»ŸæˆåŠŸç‡: {benchmark_results['success_rate']:.1%}")
        print(f"  æ•…éšœæ¢å¤æ—¶é—´: {benchmark_results['fault_recovery_time']:.2f}s")
        
        # æ€§èƒ½ç­‰çº§è¯„ä¼°
        performance_score = self._calculate_performance_score(benchmark_results)
        print(f"\nç³»ç»Ÿæ€§èƒ½è¯„åˆ†: {performance_score:.1f}/100")
        
        if performance_score >= 90:
            print("ğŸ† æ€§èƒ½ç­‰çº§: ä¼˜ç§€ (ç”Ÿäº§å°±ç»ª)")
        elif performance_score >= 80:
            print("ğŸ¥‰ æ€§èƒ½ç­‰çº§: è‰¯å¥½ (å¯ä»¥éƒ¨ç½²)")
        elif performance_score >= 70:
            print("âš ï¸  æ€§èƒ½ç­‰çº§: ä¸€èˆ¬ (éœ€è¦ä¼˜åŒ–)")
        else:
            print("âŒ æ€§èƒ½ç­‰çº§: è¾ƒå·® (éœ€è¦é‡æ„)")
        
        print(f"{'='*50}\n")
        
        # åŸºå‡†æ–­è¨€
        assert benchmark_results['signal_latency_avg'] < 20, "å¹³å‡å»¶è¿Ÿåº”è¯¥å°äº20ms"
        assert benchmark_results['throughput_tps'] > 3000, "ååé‡åº”è¯¥å¤§äº3000 TPS"
        assert benchmark_results['success_rate'] > 0.95, "æˆåŠŸç‡åº”è¯¥å¤§äº95%"
    
    async def _benchmark_latency(self):
        """å»¶è¿ŸåŸºå‡†æµ‹è¯•"""
        processor = IntegratedHFTSignalProcessor()
        latencies = []
        
        for _ in range(100):
            test_data = {
                'symbol': 'BTCUSDT',
                'price': 45000.0,
                'volume': 1000,
                'timestamp': datetime.now().timestamp() * 1000
            }
            
            start = time.perf_counter()
            await processor.process_signal(test_data)
            end = time.perf_counter()
            
            latencies.append((end - start) * 1000)
        
        return {
            'avg': statistics.mean(latencies),
            'p99': statistics.quantiles(latencies, n=100)[98]
        }
    
    async def _benchmark_throughput(self):
        """ååé‡åŸºå‡†æµ‹è¯•"""
        processor = IntegratedHFTSignalProcessor()
        batch_size = 500
        
        tasks = []
        for i in range(batch_size):
            test_data = {
                'symbol': f'TEST{i}USDT',
                'price': 45000.0 + i,
                'volume': 1000 + i,
                'timestamp': datetime.now().timestamp() * 1000 + i
            }
            tasks.append(processor.process_signal(test_data))
        
        start = time.perf_counter()
        results = await asyncio.gather(*tasks, return_exceptions=True)
        end = time.perf_counter()
        
        total_time = end - start
        successful = sum(1 for r in results if not isinstance(r, Exception))
        
        return {'tps': successful / total_time}
    
    def _benchmark_memory(self):
        """å†…å­˜åŸºå‡†æµ‹è¯•"""
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024
        
        # å†…å­˜å‹åŠ›æµ‹è¯•
        components = [
            LatencyMonitor(threshold_ms=100),
            IntegratedHFTSignalProcessor(),
            SmartOrderRouter(),
            FaultToleranceManager()
        ]
        
        # æ¨¡æ‹Ÿå¤§é‡æ“ä½œ
        for _ in range(1000):
            pass
        
        peak_memory = process.memory_info().rss / 1024 / 1024
        return {'peak_mb': peak_memory}
    
    async def _benchmark_reliability(self):
        """å¯é æ€§åŸºå‡†æµ‹è¯•"""
        fault_manager = FaultToleranceManager()
        
        # æ³¨å†Œæµ‹è¯•ç»„ä»¶
        test_component = Mock()
        test_component.recover.return_value = True
        fault_manager.register_component("test", test_component)
        
        # æ¨¡æ‹Ÿæ•…éšœå’Œæ¢å¤
        start_time = time.perf_counter()
        await fault_manager.handle_component_failure("test", Exception("test error"))
        recovery_success = await fault_manager.attempt_recovery("test")
        end_time = time.perf_counter()
        
        return {
            'success_rate': 1.0 if recovery_success else 0.0,
            'recovery_time': end_time - start_time
        }
    
    def _calculate_performance_score(self, results):
        """è®¡ç®—æ€§èƒ½è¯„åˆ†"""
        score = 0
        
        # å»¶è¿Ÿè¯„åˆ† (30åˆ†)
        if results['signal_latency_avg'] < 10:
            score += 30
        elif results['signal_latency_avg'] < 20:
            score += 20
        elif results['signal_latency_avg'] < 50:
            score += 10
        
        # ååé‡è¯„åˆ† (30åˆ†)
        if results['throughput_tps'] > 10000:
            score += 30
        elif results['throughput_tps'] > 5000:
            score += 20
        elif results['throughput_tps'] > 1000:
            score += 10
        
        # æˆåŠŸç‡è¯„åˆ† (20åˆ†)
        score += results['success_rate'] * 20
        
        # å†…å­˜æ•ˆç‡è¯„åˆ† (10åˆ†)
        if results['memory_usage_mb'] < 100:
            score += 10
        elif results['memory_usage_mb'] < 200:
            score += 5
        
        # æ¢å¤æ—¶é—´è¯„åˆ† (10åˆ†)
        if results['fault_recovery_time'] < 1.0:
            score += 10
        elif results['fault_recovery_time'] < 3.0:
            score += 5
        
        return score


if __name__ == "__main__":
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    pytest.main([__file__ + "::TestSystemBenchmarks::test_system_benchmark_suite", "-v", "-s"])