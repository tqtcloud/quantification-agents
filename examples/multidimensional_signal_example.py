"""
å¤šç»´åº¦æŠ€æœ¯æŒ‡æ ‡å¼•æ“ä½¿ç”¨ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨MultiDimensionalIndicatorEngineç”Ÿæˆç»¼åˆäº¤æ˜“ä¿¡å·
"""

import asyncio
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

from src.core.engine.multidimensional_engine import MultiDimensionalIndicatorEngine
from src.core.indicators.timeframe import TimeFrame
from src.core.models.signals import SignalStrength


class MarketDataSimulator:
    """å¸‚åœºæ•°æ®æ¨¡æ‹Ÿå™¨"""
    
    @staticmethod
    def generate_trending_data(n_points: int = 200, trend_strength: float = 0.1) -> dict:
        """ç”Ÿæˆè¶‹åŠ¿æ€§æ•°æ®"""
        np.random.seed(42)
        
        # ç”ŸæˆåŸºç¡€ä»·æ ¼åºåˆ—
        base_price = 100.0
        trend = np.linspace(0, trend_strength * n_points, n_points)
        noise = np.random.normal(0, 1, n_points)
        
        closes = base_price + trend + noise
        
        # ç”ŸæˆOHLCæ•°æ®
        opens = np.roll(closes, 1)
        opens[0] = base_price
        
        # ç”Ÿæˆé«˜ä½ä»·
        daily_range = np.random.uniform(0.5, 3.0, n_points)
        highs = closes + daily_range * np.random.uniform(0.3, 1.0, n_points)
        lows = closes - daily_range * np.random.uniform(0.3, 1.0, n_points)
        
        # ç¡®ä¿ä»·æ ¼é€»è¾‘æ­£ç¡®
        for i in range(n_points):
            highs[i] = max(opens[i], closes[i], highs[i])
            lows[i] = min(opens[i], closes[i], lows[i])
        
        # ç”Ÿæˆæˆäº¤é‡ï¼ˆè¶‹åŠ¿æœŸé—´æˆäº¤é‡å¯èƒ½å¢åŠ ï¼‰
        base_volume = 10000
        volume_trend = np.linspace(0, 5000, n_points) if trend_strength > 0 else np.zeros(n_points)
        volume_noise = np.random.uniform(-2000, 2000, n_points)
        volumes = base_volume + volume_trend + volume_noise
        volumes = np.maximum(volumes, 1000)  # ç¡®ä¿æˆäº¤é‡ä¸ºæ­£
        
        return {
            'open': opens.tolist(),
            'high': highs.tolist(),
            'low': lows.tolist(),
            'close': closes.tolist(),
            'volume': volumes.tolist()
        }
    
    @staticmethod
    def generate_sideways_data(n_points: int = 200, volatility: float = 1.0) -> dict:
        """ç”Ÿæˆæ¨ªç›˜æ•´ç†æ•°æ®"""
        np.random.seed(123)
        
        base_price = 100.0
        # æ¨ªç›˜æ•°æ®ï¼šæ— æ˜æ˜¾è¶‹åŠ¿ï¼Œä½†æœ‰æ³¢åŠ¨
        noise = np.random.normal(0, volatility, n_points)
        # æ·»åŠ ä¸€äº›å‘¨æœŸæ€§æ³¢åŠ¨
        cycle = 2 * volatility * np.sin(np.linspace(0, 4*np.pi, n_points))
        
        closes = base_price + noise + cycle
        
        opens = np.roll(closes, 1)
        opens[0] = base_price
        
        daily_range = np.random.uniform(0.5, 2.5, n_points)
        highs = closes + daily_range * np.random.uniform(0.2, 0.8, n_points)
        lows = closes - daily_range * np.random.uniform(0.2, 0.8, n_points)
        
        # ç¡®ä¿ä»·æ ¼é€»è¾‘
        for i in range(n_points):
            highs[i] = max(opens[i], closes[i], highs[i])
            lows[i] = min(opens[i], closes[i], lows[i])
        
        # æ¨ªç›˜æœŸé—´æˆäº¤é‡é€šå¸¸è¾ƒä½ä¸”ç¨³å®š
        volumes = np.random.uniform(5000, 12000, n_points)
        
        return {
            'open': opens.tolist(),
            'high': highs.tolist(),
            'low': lows.tolist(),
            'close': closes.tolist(),
            'volume': volumes.tolist()
        }
    
    @staticmethod
    def generate_volatile_data(n_points: int = 200, volatility: float = 3.0) -> dict:
        """ç”Ÿæˆé«˜æ³¢åŠ¨ç‡æ•°æ®"""
        np.random.seed(789)
        
        base_price = 100.0
        # é«˜æ³¢åŠ¨ç‡ï¼šå¤§å¹…éšæœºæ³¢åŠ¨
        large_moves = np.random.choice([-1, 1], n_points) * np.random.exponential(volatility, n_points)
        noise = np.random.normal(0, volatility*0.5, n_points)
        
        closes = base_price + np.cumsum(large_moves + noise)
        
        opens = np.roll(closes, 1)
        opens[0] = base_price
        
        # é«˜æ³¢åŠ¨æœŸé—´æ—¥å†…å¹…åº¦ä¹Ÿå¤§
        daily_range = np.random.uniform(2.0, 8.0, n_points)
        highs = closes + daily_range * np.random.uniform(0.3, 1.0, n_points)
        lows = closes - daily_range * np.random.uniform(0.3, 1.0, n_points)
        
        for i in range(n_points):
            highs[i] = max(opens[i], closes[i], highs[i])
            lows[i] = min(opens[i], closes[i], lows[i])
        
        # é«˜æ³¢åŠ¨æœŸé—´æˆäº¤é‡é€šå¸¸æ¿€å¢
        volumes = np.random.uniform(15000, 35000, n_points)
        
        return {
            'open': opens.tolist(),
            'high': highs.tolist(),
            'low': lows.tolist(),
            'close': closes.tolist(),
            'volume': volumes.tolist()
        }


async def analyze_market_scenario(
    engine: MultiDimensionalIndicatorEngine,
    scenario_name: str,
    market_data: dict,
    enable_multiframe: bool = True
) -> None:
    """åˆ†æå¸‚åœºåœºæ™¯"""
    
    logger.info(f"\n{'='*60}")
    logger.info(f"åˆ†æåœºæ™¯: {scenario_name}")
    logger.info(f"{'='*60}")
    
    try:
        # ç”Ÿæˆå¤šç»´åº¦ä¿¡å·
        signal = await engine.generate_multidimensional_signal(
            symbol="DEMO/USDT",
            market_data=market_data,
            enable_multiframe_analysis=enable_multiframe
        )
        
        if signal is None:
            logger.info("âŒ æœªç”Ÿæˆæœ‰æ•ˆä¿¡å·ï¼ˆå¯èƒ½æ˜¯ä¸­æ€§å¸‚åœºï¼‰")
            return
        
        # æ˜¾ç¤ºä¸»è¦ä¿¡å·ä¿¡æ¯
        logger.info(f"ğŸ“Š ä¸»è¦ä¿¡å·:")
        logger.info(f"  â€¢ ä¿¡å·ç±»å‹: {signal.primary_signal.signal_type.name}")
        logger.info(f"  â€¢ ç½®ä¿¡åº¦: {signal.primary_signal.confidence:.3f}")
        logger.info(f"  â€¢ å…¥åœºä»·æ ¼: {signal.primary_signal.entry_price:.2f}")
        logger.info(f"  â€¢ ç›®æ ‡ä»·æ ¼: {signal.primary_signal.target_price:.2f}")
        logger.info(f"  â€¢ æ­¢æŸä»·æ ¼: {signal.primary_signal.stop_loss:.2f}")
        logger.info(f"  â€¢ é£é™©æ”¶ç›Šæ¯”: {signal.primary_signal.risk_reward_ratio:.2f}")
        
        # æ˜¾ç¤ºå¤šç»´åº¦åˆ†æ
        logger.info(f"\nğŸ” å¤šç»´åº¦åˆ†æ:")
        logger.info(f"  â€¢ åŠ¨é‡è¯„åˆ†: {signal.momentum_score:+.3f}")
        logger.info(f"  â€¢ å‡å€¼å›å½’è¯„åˆ†: {signal.mean_reversion_score:+.3f}")
        logger.info(f"  â€¢ æ³¢åŠ¨ç‡è¯„åˆ†: {signal.volatility_score:.3f}")
        logger.info(f"  â€¢ æˆäº¤é‡è¯„åˆ†: {signal.volume_score:.3f}")
        logger.info(f"  â€¢ æƒ…ç»ªè¯„åˆ†: {signal.sentiment_score:+.3f}")
        logger.info(f"  â€¢ ç»¼åˆç½®ä¿¡åº¦: {signal.overall_confidence:.3f}")
        
        # æ˜¾ç¤ºè´¨é‡è¯„ä¼°
        logger.info(f"\nğŸ“ˆ ä¿¡å·è´¨é‡è¯„ä¼°:")
        logger.info(f"  â€¢ ä¿¡å·è´¨é‡è¯„åˆ†: {signal.signal_quality_score:.3f}")
        logger.info(f"  â€¢ æ–¹å‘ä¸€è‡´æ€§: {signal.signal_direction_consensus:+.3f}")
        logger.info(f"  â€¢ å¸‚åœºçŠ¶æ€: {signal.market_regime}")
        logger.info(f"  â€¢ å»ºè®®æœ€å¤§ä»“ä½: {signal.max_position_size:.1%}")
        
        # æ˜¾ç¤ºä»“ä½å»ºè®®
        conservative_position = signal.get_position_sizing_recommendation(
            base_position_size=1.0, risk_tolerance=0.5
        )
        aggressive_position = signal.get_position_sizing_recommendation(
            base_position_size=1.0, risk_tolerance=1.0
        )
        
        logger.info(f"\nğŸ’¼ ä»“ä½å»ºè®®:")
        logger.info(f"  â€¢ ä¿å®ˆç­–ç•¥: {conservative_position:.1%}")
        logger.info(f"  â€¢ ç§¯æç­–ç•¥: {aggressive_position:.1%}")
        
        # æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
        logger.info(f"\nğŸ§  å†³ç­–æ¨ç†:")
        for i, reason in enumerate(signal.primary_signal.reasoning, 1):
            logger.info(f"  {i}. {reason}")
        
        # æ˜¾ç¤ºæŠ€æœ¯ä½ä¿¡æ¯
        if signal.technical_levels:
            logger.info(f"\nğŸ“ å…³é”®æŠ€æœ¯ä½:")
            for level_name, level_price in signal.technical_levels.items():
                logger.info(f"  â€¢ {level_name}: {level_price:.2f}")
        
    except Exception as e:
        logger.error(f"âŒ åˆ†æåœºæ™¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")


async def performance_comparison():
    """æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
    logger.info(f"\n{'='*60}")
    logger.info("æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    logger.info(f"{'='*60}")
    
    # æµ‹è¯•ä¸åŒå·¥ä½œçº¿ç¨‹æ•°çš„æ€§èƒ½
    import time
    
    test_data = MarketDataSimulator.generate_trending_data(500, 0.2)
    
    for workers in [2, 4, 8]:
        engine = MultiDimensionalIndicatorEngine(max_workers=workers)
        
        try:
            start_time = time.time()
            
            # å¹¶å‘ç”Ÿæˆå¤šä¸ªä¿¡å·
            tasks = []
            for i in range(10):
                task = engine.generate_multidimensional_signal(
                    f"TEST{i}/USDT",
                    test_data,
                    enable_multiframe_analysis=True
                )
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            # ç»Ÿè®¡ç»“æœ
            successful = sum(1 for r in results if not isinstance(r, Exception))
            failed = len(results) - successful
            
            logger.info(f"å·¥ä½œçº¿ç¨‹æ•°: {workers}")
            logger.info(f"  â€¢ å¤„ç†æ—¶é—´: {processing_time:.3f}s")
            logger.info(f"  â€¢ æˆåŠŸä¿¡å·: {successful}/10")
            logger.info(f"  â€¢ å¤±è´¥ä¿¡å·: {failed}/10")
            logger.info(f"  â€¢ å¹³å‡æ¯ä¿¡å·: {processing_time/10:.3f}s")
            
            # æ˜¾ç¤ºå¼•æ“ç»Ÿè®¡
            stats = engine.get_performance_stats()
            logger.info(f"  â€¢ å¼•æ“ç»Ÿè®¡: {stats}")
            
        finally:
            engine.cleanup()


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¤šç»´åº¦æŠ€æœ¯æŒ‡æ ‡å¼•æ“ç¤ºä¾‹")
    
    # åˆ›å»ºå¼•æ“å®ä¾‹
    engine = MultiDimensionalIndicatorEngine(max_workers=4)
    
    try:
        # 1. ä¸Šæ¶¨è¶‹åŠ¿åœºæ™¯
        trending_up_data = MarketDataSimulator.generate_trending_data(200, 0.15)
        await analyze_market_scenario(
            engine, "å¼ºåŠ¿ä¸Šæ¶¨è¶‹åŠ¿", trending_up_data, enable_multiframe=True
        )
        
        # 2. ä¸‹è·Œè¶‹åŠ¿åœºæ™¯
        trending_down_data = MarketDataSimulator.generate_trending_data(200, -0.12)
        await analyze_market_scenario(
            engine, "æ˜æ˜¾ä¸‹è·Œè¶‹åŠ¿", trending_down_data, enable_multiframe=True
        )
        
        # 3. æ¨ªç›˜æ•´ç†åœºæ™¯
        sideways_data = MarketDataSimulator.generate_sideways_data(200, 1.5)
        await analyze_market_scenario(
            engine, "æ¨ªç›˜æ•´ç†", sideways_data, enable_multiframe=False
        )
        
        # 4. é«˜æ³¢åŠ¨ç‡åœºæ™¯
        volatile_data = MarketDataSimulator.generate_volatile_data(200, 2.5)
        await analyze_market_scenario(
            engine, "é«˜æ³¢åŠ¨ç‡å¸‚åœº", volatile_data, enable_multiframe=True
        )
        
        # 5. æ€§èƒ½å¯¹æ¯”æµ‹è¯•
        await performance_comparison()
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        logger.info(f"\n{'='*60}")
        logger.info("æœ€ç»ˆå¼•æ“ç»Ÿè®¡")
        logger.info(f"{'='*60}")
        
        final_stats = engine.get_performance_stats()
        for stat_name, stat_value in final_stats.items():
            logger.info(f"{stat_name}: {stat_value}")
        
    except Exception as e:
        logger.error(f"âŒ è¿è¡Œç¤ºä¾‹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        
    finally:
        # æ¸…ç†èµ„æº
        engine.cleanup()
        logger.info("âœ… ç¤ºä¾‹è¿è¡Œå®Œæˆï¼Œèµ„æºå·²æ¸…ç†")


if __name__ == "__main__":
    # è¿è¡Œç¤ºä¾‹
    asyncio.run(main())