# DuckDBå†å²æ•°æ®å­˜å‚¨ç³»ç»Ÿ

## æ¦‚è¿°

DuckDBå­˜å‚¨ç³»ç»Ÿæ˜¯é‡åŒ–äº¤æ˜“å¹³å°çš„æ ¸å¿ƒç»„ä»¶ä¹‹ä¸€ï¼Œä¸“é—¨ç”¨äºå­˜å‚¨å’Œåˆ†æå†å²äº¤æ˜“æ•°æ®ã€‚å®ƒæä¾›é«˜æ€§èƒ½çš„OLAPæŸ¥è¯¢èƒ½åŠ›ï¼Œæ”¯æŒå¤æ‚çš„æ—¶åºæ•°æ®åˆ†æå’ŒæŠ¥è¡¨ç”Ÿæˆã€‚

## ä¸»è¦ç‰¹æ€§

### ğŸš€ é«˜æ€§èƒ½å­˜å‚¨
- **åˆ—å¼å­˜å‚¨**: ä¼˜åŒ–åˆ†æå‹æŸ¥è¯¢æ€§èƒ½
- **å‹ç¼©ä¼˜åŒ–**: æ”¯æŒå¤šç§å‹ç¼©ç®—æ³•ï¼ˆSNAPPYã€GZIPã€ZSTDç­‰ï¼‰
- **åˆ†åŒºç­–ç•¥**: åŸºäºæ—¶é—´çš„æ™ºèƒ½åˆ†åŒº
- **å¹¶å‘æ”¯æŒ**: å¤šçº¿ç¨‹å¹¶å‘è¯»å†™

### ğŸ“Š æ•°æ®æ¨¡å‹
- **å†å²å¸‚åœºæ•°æ®**: OHLCVæ•°æ®ï¼Œæ”¯æŒå¤šæ—¶é—´æ¡†æ¶
- **äº¤æ˜“ä¿¡å·å†å²**: åŒ…å«æ‰§è¡ŒçŠ¶æ€å’Œç»©æ•ˆè·Ÿè¸ª
- **è®¢å•è®°å½•**: å®Œæ•´è®¢å•ç”Ÿå‘½å‘¨æœŸè®°å½•
- **é£é™©æŒ‡æ ‡**: ç»¼åˆé£é™©è¯„ä¼°å’Œç»©æ•ˆç»Ÿè®¡

### ğŸ”„ ç”Ÿå‘½å‘¨æœŸç®¡ç†
- **è‡ªåŠ¨æ¸…ç†**: åŸºäºä¿ç•™ç­–ç•¥çš„è¿‡æœŸæ•°æ®æ¸…ç†
- **æ•°æ®å½’æ¡£**: å†å²æ•°æ®å‹ç¼©å½’æ¡£åˆ°Parquet
- **å¤‡ä»½æ¢å¤**: å®Œæ•´å’Œå¢é‡å¤‡ä»½æœºåˆ¶
- **å¥åº·ç›‘æ§**: å­˜å‚¨å¥åº·çŠ¶æ€ç›‘æ§å’ŒæŠ¥å‘Š

## å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
pip install duckdb pandas numpy pydantic
```

### åŸºæœ¬ä½¿ç”¨

```python
from src.core.storage import DuckDBStorage, StorageConfig
from src.exchanges.trading_interface import TradingEnvironment

# åˆ›å»ºå­˜å‚¨é…ç½®
config = StorageConfig(
    max_memory_gb=4.0,
    thread_count=4,
    enable_compression=True
)

# åˆå§‹åŒ–å­˜å‚¨ç³»ç»Ÿ
storage = DuckDBStorage(config=config)

# å­˜å‚¨å¸‚åœºæ•°æ®
await storage.store_historical_market_data(market_data, TradingEnvironment.TESTNET)

# æŸ¥è¯¢æ•°æ®
data = await storage.query_historical_market_data(
    symbol='BTCUSDT',
    interval='1m',
    start_time=start_time,
    end_time=end_time
)
```

## æ•°æ®æ¨¡å‹è¯¦è§£

### å†å²å¸‚åœºæ•°æ® (HistoricalMarketData)

```python
from decimal import Decimal
from datetime import datetime
from src.core.storage.models import HistoricalMarketData

market_data = HistoricalMarketData(
    timestamp=datetime.utcnow(),
    symbol='BTCUSDT',
    environment='testnet',
    interval='1m',
    open_price=Decimal('50000.00'),
    high_price=Decimal('50100.00'),
    low_price=Decimal('49900.00'),
    close_price=Decimal('50050.00'),
    volume=Decimal('1.5'),
    quote_volume=Decimal('75000.00'),
    trade_count=100,
    data_source='binance',
    metadata={'exchange': 'binance', 'quality': 'high'}
)
```

**å­—æ®µè¯´æ˜:**
- `timestamp`: æ•°æ®æ—¶é—´æˆ³
- `symbol`: äº¤æ˜“å“ç§
- `environment`: ç¯å¢ƒæ ‡è¯†ï¼ˆtestnet/mainnetï¼‰
- `interval`: æ—¶é—´é—´éš”ï¼ˆ1m, 5m, 1h, 1dç­‰ï¼‰
- `open_price/high_price/low_price/close_price`: OHLCä»·æ ¼æ•°æ®
- `volume/quote_volume`: æˆäº¤é‡æ•°æ®
- `trade_count`: æˆäº¤ç¬”æ•°
- `data_source`: æ•°æ®æ¥æº
- `metadata`: é¢å¤–å…ƒæ•°æ®

### å†å²äº¤æ˜“ä¿¡å· (HistoricalTradingSignal)

```python
from src.core.storage.models import HistoricalTradingSignal

signal = HistoricalTradingSignal(
    timestamp=datetime.utcnow(),
    symbol='BTCUSDT',
    environment='testnet',
    signal_id='momentum_001',
    source='momentum_agent',
    signal_type='momentum',
    action='BUY',
    strength=0.8,
    confidence=0.9,
    target_price=Decimal('51000.00'),
    suggested_quantity=Decimal('0.1'),
    reason='å¼ºåŠ²ä¸Šæ¶¨åŠ¨é‡ä¿¡å·',
    technical_context={
        'rsi': 35,
        'macd': 0.05,
        'volume_ratio': 1.5
    }
)
```

**å…³é”®å­—æ®µ:**
- `signal_id`: ä¿¡å·å”¯ä¸€æ ‡è¯†ç¬¦
- `source`: ä¿¡å·æ¥æºï¼ˆAgentåç§°ï¼‰
- `action`: äº¤æ˜“åŠ¨ä½œï¼ˆBUY/SELL/HOLDï¼‰
- `strength`: ä¿¡å·å¼ºåº¦ï¼ˆ-1åˆ°1ï¼‰
- `confidence`: ä¿¡å·ç½®ä¿¡åº¦ï¼ˆ0åˆ°1ï¼‰
- `execution_status`: æ‰§è¡ŒçŠ¶æ€
- `realized_pnl`: å·²å®ç°ç›ˆäº

### å†å²è®¢å•è®°å½• (HistoricalOrderRecord)

```python
from src.core.storage.models import HistoricalOrderRecord

order = HistoricalOrderRecord(
    timestamp=datetime.utcnow(),
    symbol='BTCUSDT',
    environment='testnet',
    order_id='order_123',
    client_order_id='client_123',
    side='BUY',
    order_type='LIMIT',
    quantity=Decimal('0.1'),
    price=Decimal('50000.00'),
    status='FILLED',
    executed_qty=Decimal('0.1'),
    avg_price=Decimal('50050.00'),
    commission=Decimal('5.00'),
    commission_asset='USDT',
    realized_pnl=Decimal('25.00')
)
```

**æ ¸å¿ƒå­—æ®µ:**
- `order_id`: äº¤æ˜“æ‰€è®¢å•ID
- `client_order_id`: å®¢æˆ·ç«¯è®¢å•ID
- `side`: ä¹°å–æ–¹å‘
- `order_type`: è®¢å•ç±»å‹
- `status`: è®¢å•çŠ¶æ€
- `executed_qty`: å·²æ‰§è¡Œæ•°é‡
- `realized_pnl`: å·²å®ç°ç›ˆäº

### å†å²é£é™©æŒ‡æ ‡ (HistoricalRiskMetrics)

```python
from src.core.storage.models import HistoricalRiskMetrics

risk_metrics = HistoricalRiskMetrics(
    timestamp=datetime.utcnow(),
    environment='testnet',
    calculation_period='1h',
    total_balance=Decimal('10000.00'),
    effective_leverage=2.0,
    max_drawdown=0.05,
    current_drawdown=0.02,
    var_95=Decimal('-100.00'),
    sharpe_ratio=1.5,
    win_rate=0.65,
    profit_factor=2.1
)
```

**é‡è¦æŒ‡æ ‡:**
- `effective_leverage`: æœ‰æ•ˆæ æ†
- `max_drawdown`: æœ€å¤§å›æ’¤
- `var_95`: 95%ç½®ä¿¡åº¦VaR
- `sharpe_ratio`: å¤æ™®æ¯”ç‡
- `profit_factor`: ç›ˆåˆ©å› å­

## é…ç½®é€‰é¡¹

### StorageConfig

```python
from src.core.storage.models import StorageConfig, CompressionType

config = StorageConfig(
    # åŸºæœ¬é…ç½®
    max_memory_gb=4.0,          # æœ€å¤§å†…å­˜ä½¿ç”¨
    thread_count=4,             # çº¿ç¨‹æ•°
    checkpoint_threshold_gb=2.0, # æ£€æŸ¥ç‚¹é˜ˆå€¼
    
    # å‹ç¼©é…ç½®
    default_compression=CompressionType.SNAPPY,
    enable_compression=True,
    
    # åˆ†åŒºé…ç½®
    partition_strategy=PartitionStrategy.MONTHLY,
    enable_partitioning=True,
    
    # ä¼˜åŒ–é…ç½®
    auto_optimize=True,
    optimize_interval_hours=24
)
```

### DataRetentionPolicy

```python
from src.core.storage.models import DataRetentionPolicy

retention = DataRetentionPolicy(
    # æ•°æ®ä¿ç•™æœŸï¼ˆå¤©æ•°ï¼‰
    market_data_retention_days=365,     # å¸‚åœºæ•°æ®1å¹´
    signal_retention_days=180,          # ä¿¡å·åŠå¹´
    order_retention_days=730,           # è®¢å•2å¹´
    risk_metrics_retention_days=365,    # é£é™©æŒ‡æ ‡1å¹´
    
    # å‹ç¼©å’Œå½’æ¡£
    compress_after_days=30,
    archive_after_days=90,
    
    # è‡ªåŠ¨æ¸…ç†
    enable_auto_cleanup=True,
    cleanup_interval_hours=24
)
```

## APIå‚è€ƒ

### DuckDBStorage

#### æ•°æ®å­˜å‚¨æ–¹æ³•

```python
# å¼‚æ­¥å­˜å‚¨å¸‚åœºæ•°æ®
await storage.store_historical_market_data(
    data: List[HistoricalMarketData],
    environment: TradingEnvironment
) -> int

# å¼‚æ­¥å­˜å‚¨äº¤æ˜“ä¿¡å·
await storage.store_historical_trading_signals(
    signals: List[HistoricalTradingSignal],
    environment: TradingEnvironment
) -> int

# å¼‚æ­¥å­˜å‚¨è®¢å•è®°å½•
await storage.store_historical_order_records(
    orders: List[HistoricalOrderRecord],
    environment: TradingEnvironment
) -> int

# å¼‚æ­¥å­˜å‚¨é£é™©æŒ‡æ ‡
await storage.store_historical_risk_metrics(
    metrics: List[HistoricalRiskMetrics],
    environment: TradingEnvironment
) -> int
```

#### æ•°æ®æŸ¥è¯¢æ–¹æ³•

```python
# æŸ¥è¯¢å†å²å¸‚åœºæ•°æ®
await storage.query_historical_market_data(
    symbol: str,
    interval: str,
    start_time: datetime,
    end_time: datetime,
    environment: TradingEnvironment,
    limit: Optional[int] = None
) -> List[Dict[str, Any]]

# æŸ¥è¯¢å†å²äº¤æ˜“ä¿¡å·
await storage.query_historical_trading_signals(
    symbol: Optional[str] = None,
    source: Optional[str] = None,
    signal_type: Optional[str] = None,
    start_time: Optional[datetime] = None,
    end_time: Optional[datetime] = None,
    environment: TradingEnvironment,
    limit: Optional[int] = 1000
) -> List[Dict[str, Any]]
```

#### åˆ†ææŸ¥è¯¢æ–¹æ³•

```python
# è·å–äº¤æ˜“ç»©æ•ˆåˆ†æ
await storage.get_trading_performance_analysis(
    symbol: Optional[str] = None,
    strategy_id: Optional[str] = None,
    start_time: Optional[datetime] = None,
    end_time: Optional[datetime] = None,
    environment: TradingEnvironment
) -> Dict[str, Any]

# è·å–å­˜å‚¨ç»Ÿè®¡
await storage.get_storage_statistics(
    environment: TradingEnvironment
) -> Dict[str, Any]
```

#### ç”Ÿå‘½å‘¨æœŸç®¡ç†

```python
# æ¸…ç†è¿‡æœŸæ•°æ®
await storage.cleanup_expired_data(
    environment: TradingEnvironment
) -> Dict[str, int]

# å¯¼å‡ºæ•°æ®åˆ°Parquet
await storage.export_data_to_parquet(
    table_name: str,
    output_path: Path,
    start_time: Optional[datetime] = None,
    end_time: Optional[datetime] = None,
    environment: TradingEnvironment
) -> bool
```

### DataMigrationManager

```python
from src.core.storage.data_migration import DataMigrationManager

migration_manager = DataMigrationManager()

# åˆ›å»ºå¤‡ä»½
backup_info = await migration_manager.create_backup(
    environment=TradingEnvironment.TESTNET,
    backup_type="incremental"  # or "full"
)

# æ•°æ®å½’æ¡£
archive_result = await migration_manager.archive_old_data(
    environment=TradingEnvironment.TESTNET,
    archive_before_days=90
)

# å­˜å‚¨ä¼˜åŒ–
optimization_result = await migration_manager.optimize_storage(
    environment=TradingEnvironment.TESTNET
)

# è·å–å¥åº·æŠ¥å‘Š
health_report = migration_manager.get_storage_health_report(
    environment=TradingEnvironment.TESTNET
)
```

## æ€§èƒ½ä¼˜åŒ–

### æŸ¥è¯¢ä¼˜åŒ–

1. **ä½¿ç”¨é€‚å½“çš„æ—¶é—´èŒƒå›´**
```python
# å¥½çš„å®è·µï¼šé™åˆ¶æŸ¥è¯¢æ—¶é—´èŒƒå›´
data = await storage.query_historical_market_data(
    symbol='BTCUSDT',
    interval='1m',
    start_time=datetime.utcnow() - timedelta(hours=1),
    end_time=datetime.utcnow(),
    limit=100
)
```

2. **åˆ©ç”¨ç´¢å¼•**
```python
# æŸ¥è¯¢ä¼šåˆ©ç”¨ä»¥ä¸‹ç´¢å¼•ï¼š
# - (symbol, timestamp)
# - (interval, timestamp)  
# - (environment, timestamp)
```

3. **æ‰¹é‡æ“ä½œ**
```python
# æ‰¹é‡å­˜å‚¨è€Œä¸æ˜¯å•æ¡å­˜å‚¨
await storage.store_historical_market_data(batch_data, env)
```

### å­˜å‚¨ä¼˜åŒ–

1. **å®šæœŸä¼˜åŒ–è¡¨ç»“æ„**
```python
# æ‰‹åŠ¨è§¦å‘å­˜å‚¨ä¼˜åŒ–
await migration_manager.optimize_storage(TradingEnvironment.TESTNET)
```

2. **é…ç½®åˆé€‚çš„å†…å­˜é™åˆ¶**
```python
config = StorageConfig(
    max_memory_gb=8.0,  # æ ¹æ®ç³»ç»Ÿå†…å­˜è°ƒæ•´
    thread_count=6      # æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´
)
```

3. **ä½¿ç”¨å‹ç¼©**
```python
config = StorageConfig(
    enable_compression=True,
    default_compression=CompressionType.SNAPPY  # å¹³è¡¡å‹ç¼©ç‡å’Œæ€§èƒ½
)
```

## ç›‘æ§å’Œç»´æŠ¤

### å­˜å‚¨ç›‘æ§

```python
# è·å–å­˜å‚¨ç»Ÿè®¡
stats = await storage.get_storage_statistics(TradingEnvironment.TESTNET)
print(f"æ•°æ®åº“å¤§å°: {stats['file_size_mb']} MB")
print(f"æ€»è®°å½•æ•°: {stats['total_rows']}")

# è·å–å¥åº·æŠ¥å‘Š
health = migration_manager.get_storage_health_report(TradingEnvironment.TESTNET)
print(f"å¥åº·è¯„åˆ†: {health['health_score']}/100")
```

### å®šæœŸç»´æŠ¤ä»»åŠ¡

```python
async def daily_maintenance():
    """æ¯æ—¥ç»´æŠ¤ä»»åŠ¡"""
    # 1. æ¸…ç†è¿‡æœŸæ•°æ®
    await storage.cleanup_expired_data(TradingEnvironment.TESTNET)
    
    # 2. åˆ›å»ºå¢é‡å¤‡ä»½
    await migration_manager.create_backup(
        TradingEnvironment.TESTNET, 
        "incremental"
    )
    
    # 3. å­˜å‚¨ä¼˜åŒ–
    await migration_manager.optimize_storage(TradingEnvironment.TESTNET)
    
    # 4. å¥åº·æ£€æŸ¥
    health = migration_manager.get_storage_health_report(TradingEnvironment.TESTNET)
    if health['health_score'] < 80:
        print(f"å­˜å‚¨å¥åº·è­¦å‘Š: {health['recommendations']}")
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å†…å­˜ä¸è¶³é”™è¯¯**
```python
# è§£å†³æ–¹æ¡ˆï¼šå‡å°‘å†…å­˜ä½¿ç”¨æˆ–å¢åŠ ç³»ç»Ÿå†…å­˜
config = StorageConfig(max_memory_gb=2.0)  # å‡å°‘å†…å­˜é™åˆ¶
```

2. **æŸ¥è¯¢æ€§èƒ½æ…¢**
```python
# è§£å†³æ–¹æ¡ˆï¼š
# - ç¼©å°æŸ¥è¯¢æ—¶é—´èŒƒå›´
# - æ·»åŠ LIMITé™åˆ¶
# - å®šæœŸæ‰§è¡Œå­˜å‚¨ä¼˜åŒ–
```

3. **æ•°æ®åº“æ–‡ä»¶è¿‡å¤§**
```python
# è§£å†³æ–¹æ¡ˆï¼š
# - å‡å°‘æ•°æ®ä¿ç•™æœŸ
# - å¯ç”¨æ•°æ®å‹ç¼©å’Œå½’æ¡£
# - å®šæœŸæ¸…ç†è¿‡æœŸæ•°æ®
```

### æ—¥å¿—è®°å½•

å­˜å‚¨ç³»ç»Ÿä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—è®°å½•ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æŸ¥çœ‹æ—¥å¿—ï¼š

```python
import logging
logging.basicConfig(level=logging.INFO)
```

å…³é”®æ—¥å¿—æ¶ˆæ¯åŒ…æ‹¬ï¼š
- æ•°æ®å­˜å‚¨æ“ä½œ
- æŸ¥è¯¢æ€§èƒ½ç»Ÿè®¡
- ç»´æŠ¤ä»»åŠ¡æ‰§è¡Œ
- é”™è¯¯å’Œè­¦å‘Šä¿¡æ¯

## æœ€ä½³å®è·µ

### 1. æ•°æ®æ¨¡å‹è®¾è®¡
- ä½¿ç”¨å¼ºç±»å‹æ•°æ®æ¨¡å‹ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
- åˆç†è®¾ç½®å­—æ®µéªŒè¯è§„åˆ™
- ä¸ºé‡è¦æ•°æ®æ·»åŠ å…ƒæ•°æ®å­—æ®µ

### 2. æ€§èƒ½ä¼˜åŒ–
- æ‰¹é‡æ“ä½œä¼˜äºå•æ¡æ“ä½œ
- åˆç†è®¾ç½®æŸ¥è¯¢æ—¶é—´èŒƒå›´
- å®šæœŸæ‰§è¡Œå­˜å‚¨ä¼˜åŒ–

### 3. æ•°æ®ç®¡ç†
- é…ç½®åˆé€‚çš„æ•°æ®ä¿ç•™ç­–ç•¥
- å®šæœŸåˆ›å»ºå¤‡ä»½
- ç›‘æ§å­˜å‚¨å¥åº·çŠ¶æ€

### 4. é”™è¯¯å¤„ç†
- å®ç°é‡è¯•æœºåˆ¶å¤„ç†ä¸´æ—¶æ•…éšœ
- è®°å½•è¯¦ç»†çš„é”™è¯¯æ—¥å¿—
- ç›‘æ§æ•°æ®è´¨é‡æŒ‡æ ‡

## ç¤ºä¾‹ä»£ç 

å®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹è¯·å‚è€ƒï¼š
- `/examples/storage/duckdb_storage_example.py`
- `/tests/core/storage/test_duckdb_storage.py`

## æ‰©å±•åŠŸèƒ½

### è‡ªå®šä¹‰åˆ†ææŸ¥è¯¢

```python
# è‡ªå®šä¹‰SQLæŸ¥è¯¢ç¤ºä¾‹
async def custom_analysis(storage, environment):
    conn = storage.duckdb_manager.get_connection(environment)
    
    # è®¡ç®—æ¯æ—¥æ”¶ç›Šç‡
    query = """
    SELECT 
        DATE_TRUNC('day', timestamp) as date,
        symbol,
        FIRST(close_price ORDER BY timestamp) as day_open,
        LAST(close_price ORDER BY timestamp) as day_close,
        (LAST(close_price ORDER BY timestamp) - FIRST(close_price ORDER BY timestamp)) 
        / FIRST(close_price ORDER BY timestamp) as daily_return
    FROM historical_market_data
    WHERE symbol = 'BTCUSDT' AND interval = '1m'
    GROUP BY DATE_TRUNC('day', timestamp), symbol
    ORDER BY date
    """
    
    result = conn.execute(query).fetchdf()
    return result
```

### é›†æˆå¤–éƒ¨æ•°æ®æº

```python
# ä»å¤–éƒ¨APIå¯¼å…¥æ•°æ®
async def import_external_data(storage):
    # ä»APIè·å–æ•°æ®
    external_data = await fetch_from_api()
    
    # è½¬æ¢ä¸ºå†…éƒ¨æ•°æ®æ¨¡å‹
    market_data = [
        HistoricalMarketData(**item) 
        for item in external_data
    ]
    
    # å­˜å‚¨åˆ°DuckDB
    await storage.store_historical_market_data(
        market_data, 
        TradingEnvironment.TESTNET
    )
```

## æ€»ç»“

DuckDBå­˜å‚¨ç³»ç»Ÿæä¾›äº†å®Œæ•´çš„å†å²æ•°æ®ç®¡ç†è§£å†³æ–¹æ¡ˆï¼Œå…·æœ‰ä»¥ä¸‹æ ¸å¿ƒä¼˜åŠ¿ï¼š

- **é«˜æ€§èƒ½**: åˆ—å¼å­˜å‚¨å’Œå‹ç¼©ä¼˜åŒ–
- **å¯æ‰©å±•**: æ”¯æŒå¤§æ•°æ®é‡å­˜å‚¨å’Œåˆ†æ
- **æ˜“ç”¨æ€§**: ç®€æ´çš„APIå’Œå¼ºç±»å‹æ¨¡å‹
- **å¯é æ€§**: å®Œæ•´çš„å¤‡ä»½æ¢å¤æœºåˆ¶
- **å¯ç»´æŠ¤**: è‡ªåŠ¨åŒ–ç”Ÿå‘½å‘¨æœŸç®¡ç†

é€šè¿‡åˆç†é…ç½®å’Œä½¿ç”¨ï¼ŒDuckDBå­˜å‚¨ç³»ç»Ÿå¯ä»¥æ»¡è¶³é‡åŒ–äº¤æ˜“ç³»ç»Ÿå¯¹å†å²æ•°æ®å­˜å‚¨å’Œåˆ†æçš„æ‰€æœ‰éœ€æ±‚ã€‚