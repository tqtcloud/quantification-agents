# åŒç­–ç•¥ç®¡ç†ç³»ç»Ÿæµ‹è¯•æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»äº†åŒç­–ç•¥ç®¡ç†å’Œéš”ç¦»ç³»ç»Ÿçš„å®Œæ•´æµ‹è¯•éªŒè¯å¥—ä»¶ï¼ŒåŒ…æ‹¬é›†æˆæµ‹è¯•ã€æ€§èƒ½åŸºå‡†æµ‹è¯•ã€å¯é æ€§æµ‹è¯•å’Œæµ‹è¯•æŠ¥å‘Šç”Ÿæˆã€‚

## ğŸ“‹ æµ‹è¯•å¥—ä»¶ç»„æˆ

### 1. æ ¸å¿ƒæµ‹è¯•æ–‡ä»¶

```
tests/strategy/
â”œâ”€â”€ conftest.py                          # æµ‹è¯•é…ç½®å’Œfixture
â”œâ”€â”€ test_integration_dual_strategy.py    # åŒç­–ç•¥é›†æˆæµ‹è¯•
â”œâ”€â”€ test_performance_benchmarks.py       # æ€§èƒ½åŸºå‡†æµ‹è¯•
â”œâ”€â”€ test_reliability_and_recovery.py     # å¯é æ€§å’Œæ¢å¤æµ‹è¯•
â””â”€â”€ test_strategy_manager.py            # ç­–ç•¥ç®¡ç†å™¨æµ‹è¯•ï¼ˆå·²å­˜åœ¨ï¼‰
```

### 2. æµ‹è¯•æ‰§è¡Œè„šæœ¬

```
scripts/
â”œâ”€â”€ run_strategy_integration_tests.sh    # å®Œæ•´æµ‹è¯•å¥—ä»¶æ‰§è¡Œè„šæœ¬
â””â”€â”€ run_strategy_quick_tests.sh         # å¿«é€ŸéªŒè¯è„šæœ¬
```

### 3. æµ‹è¯•é…ç½®æ–‡ä»¶

```
â”œâ”€â”€ pytest.ini          # pytesté…ç½®
â”œâ”€â”€ .coveragerc         # è¦†ç›–ç‡é…ç½®
â””â”€â”€ tests/utils/test_report_generator.py  # æŠ¥å‘Šç”Ÿæˆå™¨
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

1. **å¿«é€ŸéªŒè¯**ï¼ˆæ¨èç”¨äºå¼€å‘å’ŒCIï¼‰ï¼š
```bash
./scripts/run_strategy_quick_tests.sh
```

2. **å®Œæ•´æµ‹è¯•å¥—ä»¶**ï¼š
```bash
./scripts/run_strategy_integration_tests.sh
```

3. **ç‰¹å®šæµ‹è¯•ç±»å‹**ï¼š
```bash
# åªè¿è¡Œé›†æˆæµ‹è¯•
./scripts/run_strategy_integration_tests.sh integration

# åªè¿è¡Œæ€§èƒ½æµ‹è¯•
./scripts/run_strategy_integration_tests.sh performance

# åªè¿è¡Œå¯é æ€§æµ‹è¯•
./scripts/run_strategy_integration_tests.sh reliability
```

### å‘½ä»¤è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰ç­–ç•¥æµ‹è¯•
uv run pytest tests/strategy/

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
uv run pytest tests/strategy/test_integration_dual_strategy.py

# è¿è¡Œç‰¹å®šæµ‹è¯•ç±»
uv run pytest tests/strategy/test_integration_dual_strategy.py::TestDualStrategyIntegration

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–¹æ³•
uv run pytest tests/strategy/test_integration_dual_strategy.py::TestDualStrategyIntegration::test_dual_strategy_lifecycle

# è¿è¡Œå¸¦æ ‡è®°çš„æµ‹è¯•
uv run pytest -m "integration"
uv run pytest -m "performance"
uv run pytest -m "not slow"
```

## ğŸ“Š æµ‹è¯•ç±»å‹è¯¦è§£

### 1. é›†æˆæµ‹è¯• (`test_integration_dual_strategy.py`)

**æµ‹è¯•ç›®æ ‡**ï¼šéªŒè¯HFTå’ŒAIç­–ç•¥çš„å®Œæ•´é›†æˆæµç¨‹

**å…³é”®æµ‹è¯•ç”¨ä¾‹**ï¼š
- âœ… `test_dual_strategy_lifecycle` - åŒç­–ç•¥å®Œæ•´ç”Ÿå‘½å‘¨æœŸ
- âœ… `test_resource_isolation` - èµ„æºéš”ç¦»æ•ˆæœ  
- âœ… `test_signal_aggregation_end_to_end` - ä¿¡å·èšåˆç«¯åˆ°ç«¯
- âœ… `test_conflict_detection_and_resolution` - å†²çªæ£€æµ‹å’Œè§£å†³
- âœ… `test_monitoring_and_alerts` - ç›‘æ§å‘Šè­¦åŠŸèƒ½
- âœ… `test_strategy_priority_management` - ä¼˜å…ˆçº§åŠ¨æ€è°ƒæ•´
- âœ… `test_strategy_failure_isolation` - ç­–ç•¥æ•…éšœéš”ç¦»
- âœ… `test_concurrent_strategy_operations` - å¹¶å‘ç­–ç•¥æ“ä½œ

**æ€§èƒ½ç›®æ ‡**ï¼š
- ç­–ç•¥å¯åŠ¨æ—¶é—´ < 5ç§’
- ä¿¡å·èšåˆå»¶è¿Ÿ < 100ms
- èµ„æºéš”ç¦»æ•ˆç‡ > 95%

### 2. æ€§èƒ½åŸºå‡†æµ‹è¯• (`test_performance_benchmarks.py`)

**æµ‹è¯•ç›®æ ‡**ï¼šéªŒè¯ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡è¾¾åˆ°é¢„æœŸæ ‡å‡†

**å…³é”®æµ‹è¯•ç”¨ä¾‹**ï¼š
- âš¡ `test_signal_aggregation_latency` - ä¿¡å·èšåˆå»¶è¿Ÿæµ‹è¯•
- ğŸ”„ `test_concurrent_signal_processing` - å¹¶å‘ä¿¡å·å¤„ç†æ€§èƒ½
- ğŸ’¾ `test_memory_usage_under_load` - è´Ÿè½½ä¸‹å†…å­˜ä½¿ç”¨
- ğŸ“ˆ `test_resource_allocation_performance` - èµ„æºåˆ†é…æ€§èƒ½
- ğŸ“Š `test_strategy_manager_scalability` - ç­–ç•¥ç®¡ç†å™¨å¯æ‰©å±•æ€§
- ğŸ”¥ `test_system_stability_under_stress` - å‹åŠ›ä¸‹ç³»ç»Ÿç¨³å®šæ€§

**æ€§èƒ½ç›®æ ‡**ï¼š
- å¹³å‡å»¶è¿Ÿ < 10ms
- P95å»¶è¿Ÿ < 20ms
- ååé‡ > 1,000 TPS
- å†…å­˜ä½¿ç”¨ < 512MB
- CPUä½¿ç”¨ < 80%

### 3. å¯é æ€§å’Œæ¢å¤æµ‹è¯• (`test_reliability_and_recovery.py`)

**æµ‹è¯•ç›®æ ‡**ï¼šéªŒè¯ç³»ç»Ÿåœ¨å¼‚å¸¸æƒ…å†µä¸‹çš„å¯é æ€§å’Œæ¢å¤èƒ½åŠ›

**å…³é”®æµ‹è¯•ç”¨ä¾‹**ï¼š
- ğŸ›¡ï¸ `test_strategy_failure_isolation` - ç­–ç•¥æ•…éšœéš”ç¦»
- ğŸ”„ `test_automatic_recovery` - è‡ªåŠ¨æ¢å¤æœºåˆ¶
- ğŸ’¾ `test_data_consistency_during_failures` - æ•…éšœæ—¶æ•°æ®ä¸€è‡´æ€§
- ğŸ§¹ `test_resource_cleanup_on_failure` - æ•…éšœæ—¶èµ„æºæ¸…ç†
- âš¡ `test_concurrent_failure_handling` - å¹¶å‘æ•…éšœå¤„ç†
- ğŸ“¡ `test_message_bus_failure_resilience` - æ¶ˆæ¯æ€»çº¿æ•…éšœå¼¹æ€§
- ğŸ¯ `test_edge_case_signal_processing` - è¾¹ç•Œæ¡ä»¶ä¿¡å·å¤„ç†
- ğŸ’¾ `test_memory_leak_prevention` - å†…å­˜æ³„æ¼é¢„é˜²

**å¯é æ€§ç›®æ ‡**ï¼š
- æ•…éšœéš”ç¦»æˆåŠŸç‡ > 99%
- è‡ªåŠ¨æ¢å¤æˆåŠŸç‡ > 95%
- æ•°æ®ä¸€è‡´æ€§ä¿éšœ 100%
- å†…å­˜æ³„æ¼é›¶å®¹å¿

## ğŸ›ï¸ æµ‹è¯•é…ç½®

### pytest.ini é…ç½®

ä¸»è¦é…ç½®é¡¹ï¼š
- æµ‹è¯•å‘ç°æ¨¡å¼
- è¦†ç›–ç‡è¦æ±‚ï¼ˆâ‰¥85%ï¼‰
- æµ‹è¯•æ ‡è®°å®šä¹‰
- æŠ¥å‘Šç”Ÿæˆé…ç½®
- å¼‚æ­¥æµ‹è¯•æ”¯æŒ

### .coveragerc é…ç½®

è¦†ç›–ç‡é…ç½®ï¼š
- æºä»£ç èŒƒå›´ï¼š`src/strategy/`
- åˆ†æ”¯è¦†ç›–ç‡å¯ç”¨
- æ’é™¤æµ‹è¯•æ–‡ä»¶å’Œä¸´æ—¶æ–‡ä»¶
- HTMLã€XMLã€JSONå¤šæ ¼å¼æŠ¥å‘Š

### æµ‹è¯•Fixture

ä¸“ç”¨fixtureï¼ˆ`tests/strategy/conftest.py`ï¼‰ï¼š
- `strategy_manager` - ç­–ç•¥ç®¡ç†å™¨å®ä¾‹
- `signal_aggregator` - ä¿¡å·èšåˆå™¨å®ä¾‹
- `resource_allocator` - èµ„æºåˆ†é…å™¨å®ä¾‹
- `integration_test_env` - é›†æˆæµ‹è¯•ç¯å¢ƒ
- `performance_monitor` - æ€§èƒ½ç›‘æ§å™¨
- `test_data_factory` - æµ‹è¯•æ•°æ®å·¥å‚

## ğŸ“ˆ æ€§èƒ½ç›‘æ§å’ŒæŒ‡æ ‡

### å…³é”®æ€§èƒ½æŒ‡æ ‡ (KPI)

1. **å»¶è¿ŸæŒ‡æ ‡**
   - å¹³å‡å»¶è¿Ÿ: < 10ms
   - P95å»¶è¿Ÿ: < 20ms
   - P99å»¶è¿Ÿ: < 50ms
   - æœ€å¤§å»¶è¿Ÿ: < 100ms

2. **ååé‡æŒ‡æ ‡**
   - ä¿¡å·å¤„ç†: > 1,000 TPS
   - ç­–ç•¥åˆ›å»º: > 100 strategies/sec
   - èµ„æºåˆ†é…: > 500 allocations/sec

3. **èµ„æºä½¿ç”¨æŒ‡æ ‡**
   - å†…å­˜ä½¿ç”¨: < 512MB
   - CPUä½¿ç”¨: < 80%
   - ç½‘ç»œè¿æ¥: < 1000
   - å­˜å‚¨ä½¿ç”¨: < 1GB

4. **å¯é æ€§æŒ‡æ ‡**
   - æˆåŠŸç‡: > 99.9%
   - æ•…éšœæ¢å¤æ—¶é—´: < 5ç§’
   - æ•°æ®ä¸€è‡´æ€§: 100%
   - å†…å­˜æ³„æ¼: 0

### æ€§èƒ½ç›‘æ§å·¥å…·

```python
# ä½¿ç”¨æ€§èƒ½ç›‘æ§fixture
async def test_my_performance(performance_monitor):
    performance_monitor.start_monitoring()
    
    # æ‰§è¡Œæµ‹è¯•ä»£ç 
    start_time = time.time()
    result = await my_function()
    latency = (time.time() - start_time) * 1000
    
    # è®°å½•æŒ‡æ ‡
    performance_monitor.record_latency(latency)
    performance_monitor.record_memory_usage(memory_mb)
    
    # è·å–æŠ¥å‘Š
    report = performance_monitor.get_summary()
    assert report['latency']['avg'] < 10.0
```

## ğŸ“ æµ‹è¯•æŠ¥å‘Š

### è‡ªåŠ¨ç”ŸæˆæŠ¥å‘Š

æµ‹è¯•æ‰§è¡Œå®Œæˆåè‡ªåŠ¨ç”Ÿæˆï¼š

1. **HTMLæŠ¥å‘Š** - å¯è§†åŒ–æµ‹è¯•ç»“æœå’Œè¦†ç›–ç‡
2. **JSONæŠ¥å‘Š** - æœºå™¨å¯è¯»çš„è¯¦ç»†æ•°æ®
3. **XMLæŠ¥å‘Š** - é€‚ç”¨äºCI/CDé›†æˆ
4. **è¦†ç›–ç‡æŠ¥å‘Š** - ä»£ç è¦†ç›–ç‡åˆ†æ

### æŠ¥å‘Šæ–‡ä»¶ä½ç½®

```
logs/
â”œâ”€â”€ strategy_test_report_YYYYMMDD_HHMMSS.html    # HTMLå¯è§†åŒ–æŠ¥å‘Š
â”œâ”€â”€ test_summary_YYYYMMDD_HHMMSS.json           # JSONæ‘˜è¦æŠ¥å‘Š
â”œâ”€â”€ coverage_html/                               # HTMLè¦†ç›–ç‡æŠ¥å‘Š
â”œâ”€â”€ coverage.xml                                 # XMLè¦†ç›–ç‡æŠ¥å‘Š
â””â”€â”€ pytest_results.xml                          # JUnit XMLç»“æœ
```

### è‡ªå®šä¹‰æŠ¥å‘Šç”Ÿæˆ

```python
# ä½¿ç”¨æŠ¥å‘Šç”Ÿæˆå™¨
from tests.utils.test_report_generator import TestReportGenerator

generator = TestReportGenerator("logs")

# è§£ææµ‹è¯•ç»“æœ
summary = generator.parse_pytest_json_report("logs/pytest_report.json")
summary.coverage_info = generator.parse_coverage_xml_report("logs/coverage.xml")

# ç”ŸæˆæŠ¥å‘Š
html_file = generator.generate_html_report(summary)
json_file = generator.generate_json_summary(summary)

print(f"HTMLæŠ¥å‘Š: {html_file}")
print(f"JSONæ‘˜è¦: {json_file}")
```

## ğŸ”§ CI/CD é›†æˆ

### GitHub Actions ç¤ºä¾‹

```yaml
name: Strategy Tests
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install uv
      run: pip install uv
    
    - name: Quick Test
      run: ./scripts/run_strategy_quick_tests.sh
    
    - name: Full Integration Test
      run: ./scripts/run_strategy_integration_tests.sh
      if: github.event_name == 'push'
    
    - name: Upload Test Results
      uses: actions/upload-artifact@v3
      with:
        name: test-results
        path: logs/
      if: always()
```

### è´¨é‡é—¨è®¾ç½®

åœ¨CIä¸­è®¾ç½®è´¨é‡é—¨ï¼š
- æµ‹è¯•é€šè¿‡ç‡ â‰¥ 95%
- ä»£ç è¦†ç›–ç‡ â‰¥ 85%
- æ€§èƒ½å›å½’æ£€æŸ¥
- å†…å­˜æ³„æ¼æ£€æµ‹

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æµ‹è¯•è¶…æ—¶**
   - æ£€æŸ¥å¼‚æ­¥æµ‹è¯•çš„awaitè¯­å¥
   - å¢åŠ timeoutè®¾ç½®
   - ä½¿ç”¨å¿«é€Ÿæµ‹è¯•è„šæœ¬è¿›è¡Œåˆæ­¥éªŒè¯

2. **å†…å­˜ä¸è¶³**
   - å‡å°‘å¹¶å‘æµ‹è¯•æ•°é‡
   - æ¸…ç†æµ‹è¯•æ•°æ®
   - ä½¿ç”¨èµ„æºé™åˆ¶fixture

3. **è¦†ç›–ç‡ä¸è¶³**
   - æ£€æŸ¥.coveragercé…ç½®
   - æ·»åŠ è¾¹ç•Œæ¡ä»¶æµ‹è¯•
   - ç§»é™¤æ— ç”¨ä»£ç 

4. **æ€§èƒ½æµ‹è¯•ä¸ç¨³å®š**
   - ä½¿ç”¨é¢„çƒ­é˜¶æ®µ
   - å¢åŠ æµ‹è¯•è¿­ä»£æ¬¡æ•°
   - æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½

### è°ƒè¯•æŠ€å·§

```bash
# è¿è¡Œå•ä¸ªå¤±è´¥çš„æµ‹è¯•
uv run pytest tests/strategy/test_integration_dual_strategy.py::test_name -vvv

# å¯ç”¨è¯¦ç»†æ—¥å¿—
uv run pytest --log-cli-level=DEBUG tests/strategy/

# åœ¨ç¬¬ä¸€ä¸ªå¤±è´¥æ—¶åœæ­¢
uv run pytest --maxfail=1 tests/strategy/

# æ˜¾ç¤ºæœ€æ…¢çš„10ä¸ªæµ‹è¯•
uv run pytest --durations=10 tests/strategy/
```

## ğŸ“š æœ€ä½³å®è·µ

### æµ‹è¯•ç¼–å†™åŸåˆ™

1. **ç‹¬ç«‹æ€§** - æµ‹è¯•ä¹‹é—´ä¸åº”æœ‰ä¾èµ–
2. **å¯é‡å¤** - ç›¸åŒæ¡ä»¶ä¸‹ç»“æœä¸€è‡´
3. **å¿«é€Ÿ** - å•å…ƒæµ‹è¯•åº”å¿«é€Ÿæ‰§è¡Œ
4. **æ¸…æ™°** - æµ‹è¯•æ„å›¾æ˜ç¡®
5. **è¦†ç›–** - æ¶µç›–æ­£å¸¸å’Œå¼‚å¸¸æƒ…å†µ

### æ€§èƒ½æµ‹è¯•å»ºè®®

1. **é¢„çƒ­** - æ‰§è¡Œæ­£å¼æµ‹è¯•å‰è¿›è¡Œé¢„çƒ­
2. **éš”ç¦»** - é¿å…æµ‹è¯•é—´ç›¸äº’å½±å“
3. **ç»Ÿè®¡** - ä½¿ç”¨ç»Ÿè®¡æ–¹æ³•è¯„ä¼°ç»“æœ
4. **é˜ˆå€¼** - è®¾å®šåˆç†çš„æ€§èƒ½é˜ˆå€¼
5. **ç›‘æ§** - æŒç»­ç›‘æ§æ€§èƒ½è¶‹åŠ¿

### å¯é æ€§æµ‹è¯•è¦ç‚¹

1. **æ•…éšœæ³¨å…¥** - ä¸»åŠ¨æ³¨å…¥å„ç§æ•…éšœ
2. **æ¢å¤éªŒè¯** - éªŒè¯è‡ªåŠ¨æ¢å¤æœºåˆ¶
3. **æ•°æ®ä¸€è‡´æ€§** - ç¡®ä¿æ•°æ®å®Œæ•´æ€§
4. **èµ„æºæ¸…ç†** - éªŒè¯èµ„æºæ­£ç¡®é‡Šæ”¾
5. **è¾¹ç•Œæ¡ä»¶** - æµ‹è¯•æç«¯æƒ…å†µ

## ğŸ¯ ä¸‹ä¸€æ­¥è®¡åˆ’

- [ ] æ·»åŠ å‹åŠ›æµ‹è¯•åœºæ™¯
- [ ] é›†æˆæ··æ²Œå·¥ç¨‹æµ‹è¯•
- [ ] ä¼˜åŒ–æµ‹è¯•æ‰§è¡Œé€Ÿåº¦  
- [ ] æ·»åŠ APIå…¼å®¹æ€§æµ‹è¯•
- [ ] å®ç°è‡ªåŠ¨åŒ–æ€§èƒ½å›å½’æ£€æµ‹

## ğŸ“ æ”¯æŒå’Œåé¦ˆ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·ï¼š
1. æŸ¥çœ‹æµ‹è¯•æ—¥å¿—æ–‡ä»¶
2. è¿è¡Œå¿«é€ŸéªŒè¯è„šæœ¬
3. æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒé…ç½®
4. æäº¤Issueåˆ°é¡¹ç›®ä»“åº“

---

**æµ‹è¯•å¥—ä»¶ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2024-12-19  
**ç»´æŠ¤è€…**: é‡åŒ–äº¤æ˜“ç³»ç»Ÿå›¢é˜Ÿ